{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of bag of words-Navie Bayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nUerp_uKl-j",
        "outputId": "91afd2db-344a-4b3c-ae25-21410b8088f7"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe13ccKNuIGW"
      },
      "source": [
        "\n",
        "df=pd.read_json('/content/gdrive/Shareddrives/Data Mining Project/english_tweets/en_2021-03-02_clean-dataset.jsonl', orient = 'records', lines = True)\n",
        "df.drop(df.columns.difference(['id','full_text', 'user']), 1, inplace=True)\n",
        "user_data = pd.json_normalize(df['user'])\n",
        "# import json\n",
        "user_data.head()\n",
        "user_data=user_data.rename(columns={\"id\":\"user_id\"})\n",
        "df = df.join(user_data)\n",
        "df.drop(df.columns.difference(['id','full_text', 'location']), 1, inplace=True)\n",
        "df.head()\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "def clean_text(text):\n",
        "#remove the emoji or other weird content (such as ðŸ‡ºðŸ‡) \n",
        "    text = ''.join(filter(lambda x: x in string.printable, text))\n",
        "#remove urls and @\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(\"RT\",\"\",text)\n",
        "    text = ' '.join(filter(lambda x:x[0]!=\"@\",text.split()))\n",
        "    text = ' '.join(filter(lambda x:x[0]!=\"&\",text.split()))\n",
        "    text= \" \".join(list(map(lambda x:x.strip(\"#\"),text.split()))) \n",
        "    return text\n",
        "\n",
        "df[\"full_text\"]=df[\"full_text\"].map(clean_text)\n",
        "\n",
        "import numpy as np\n",
        "NaN = np.nan\n",
        "df[\"label\"] = NaN\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#array_from_file = np.loadtxt(\"https://drive.google.com/file/d/13TRB0eZHumRbuHCfiFuDtN-TQwdartIe/view?usp=sharing\", dtype=str)\n",
        "\n",
        "array_from_file = ['abolishbigpharma', 'noforcedflushots', 'antivaccine', 'NoForcedVaccines',\n",
        " 'ArrestBillGates', 'notomandatoryvaccines', 'betweenmeandmydoctor',\n",
        " 'NoVaccine', 'bigpharmafia', 'NoVaccineForMe', 'bigpharmakills',\n",
        " 'novaccinemandates', 'BillGatesBioTerrorist' 'parentalrights',\n",
        " 'billgatesevil', 'parentsoverpharma', 'BillGatesIsEvil', 'saynotovaccines',\n",
        " 'billgatesisnotadoctor', 'stopmandatoryvaccination', 'billgatesvaccine',\n",
        " 'syringeslaughter', 'cdcfraud', 'fuckcovid', 'cdctruth', 'v4vglobaldemo',\n",
        " 'cdcwhistleblower', 'vaccinationchoice', 'covidvaccineispoison',\n",
        " 'VaccineAgenda', 'depopulation', 'vaccinedamage', 'DoctorsSpeakUp',\n",
        " 'vaccinefailure', 'educateb4uvax', 'vaccinefraud', 'exposebillgates',\n",
        " 'vaccineharm' 'forcedvaccines' 'vaccineinjuries' 'Fuckvaccines',\n",
        " 'vaccineinjury' 'idonotconsent' 'VaccinesAreNotTheAnswer',\n",
        " 'informedconsent' 'vaccinesarepoison' 'learntherisk' 'vaccinescause', 'nocovidshots',\n",
        " 'medicalfreedom' 'vaccineskill' 'medicalfreedomofchoice' 'vaxxed',\n",
        " 'momsofunvaccinatedchildren' 'yeht' 'mybodymychoice', 'stopvaccine', 'trackingchips',\n",
        " 'fuckthevaccine', 'fuckcovid', 'covidisfake', 'fakevaccine', 'hatevaccine', 'stopvaccine', 'stopvaccination']\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    if any(word in df.loc[idx,'full_text'] for word in array_from_file):\n",
        "    \n",
        "        df.loc[idx,'label'] = 1\n",
        "\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    df_filtered = df[df['label'] == 1]\n",
        "\n",
        "\n",
        "df_filtered.to_csv(df_filtered.to_csv(r'/content/gdrive/Shareddrives/Data Mining Project/anti_tweets/filtered-03-02.csv', index = False))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}